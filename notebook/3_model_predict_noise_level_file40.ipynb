{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13745,
     "status": "ok",
     "timestamp": 1684700463677,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "eAPbqH26tpK0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckCWUmAjuj0d"
   },
   "source": [
    "## Process weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1684696498505,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "IgjHSUdquWT5"
   },
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"../data/processed_weather_data_leuven.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping index csv column\n",
    "weather_data.drop([\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format time stamp\n",
    "weather_data[\"time\"] = pd.to_datetime(weather_data[\"time\"])\n",
    "weather_data[\"date\"] = weather_data[\"time\"].dt.date\n",
    "weather_data[\"hour\"] = weather_data[\"time\"].dt.hour\n",
    "weather_data[\"month\"] = weather_data[\"time\"].dt.month\n",
    "weather_data[\"weekday\"] = weather_data[\"time\"].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684697984611,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "8t-kbfPg0Z5E",
    "outputId": "27d84206-c5f7-4f75-f27a-a7d6c74bd2d9"
   },
   "outputs": [],
   "source": [
    "weather_data = (\n",
    "    weather_data.groupby([\"date\", \"hour\", \"month\", \"weekday\"]).mean().reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping weathercode because signal should be contained in other data + excessive amount of dummies + unseen values\n",
    "weather_data = weather_data.drop(\"weathercode\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI0hUzyA1CXN"
   },
   "source": [
    "## Process airquality data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1684698293536,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "4_cj6BEN1ByI"
   },
   "outputs": [],
   "source": [
    "air_quality_data = pd.read_csv(\"../data/processed_air_quality_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1684698304748,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "ZCWbLqLr1d0c"
   },
   "outputs": [],
   "source": [
    "# Dropping index csv column\n",
    "air_quality_data.drop([\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1684698313269,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "O_1Z9NBi1qk9",
    "outputId": "2a493110-b9c5-48ba-910c-ab23933da94f"
   },
   "outputs": [],
   "source": [
    "# extract from timestamp\n",
    "air_quality_data[\"dt\"] = pd.to_datetime(air_quality_data[\"dt\"])\n",
    "air_quality_data[\"date\"] = air_quality_data[\"dt\"].dt.date\n",
    "air_quality_data[\"hour\"] = air_quality_data[\"dt\"].dt.hour\n",
    "air_quality_data[\"month\"] = air_quality_data[\"dt\"].dt.month\n",
    "air_quality_data[\"weekday\"] = air_quality_data[\"dt\"].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1684698339552,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "_f5L1-PW2Fno",
    "outputId": "fb8100d6-1344-4642-d7b9-ffc6be121854"
   },
   "outputs": [],
   "source": [
    "air_quality_data = (\n",
    "    air_quality_data.groupby([\"date\", \"hour\", \"month\", \"weekday\"]).mean().reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzSo9TRT5wqJ"
   },
   "source": [
    "## Processing file 40 data, merge all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1684699576375,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "2DCe2abO53C3"
   },
   "outputs": [],
   "source": [
    "# Noise data\n",
    "file40 = pd.read_csv(\"../data/processed_file40_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping index csv column\n",
    "file40.drop([\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 6223,
     "status": "ok",
     "timestamp": 1684699591961,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "O4C8E1cU6IbZ",
    "outputId": "225874dd-e72b-4662-c9b8-497427558f9d"
   },
   "outputs": [],
   "source": [
    "# Convert the 'result_timestamp' column to a datetime data type\n",
    "file40[\"result_timestamp\"] = pd.to_datetime(file40[\"result_timestamp\"])\n",
    "file40[\"date\"] = file40[\"result_timestamp\"].dt.date\n",
    "file40[\"hour\"] = file40[\"result_timestamp\"].dt.hour\n",
    "file40[\"month\"] = file40[\"result_timestamp\"].dt.month\n",
    "file40[\"weekday\"] = file40[\"result_timestamp\"].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1684699643696,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "sOO0laUQ7FC6",
    "outputId": "2de39ef0-2b88-4fb2-89c5-3c66d914d730"
   },
   "outputs": [],
   "source": [
    "file40 = (\n",
    "    file40.groupby([\"object_id\", \"date\", \"hour\", \"month\", \"weekday\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1684699780525,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "9KAbyltX7TEx"
   },
   "outputs": [],
   "source": [
    "data_model_v2 = file40.merge(\n",
    "    air_quality_data,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"date\", \"hour\", \"month\", \"weekday\"],\n",
    "    right_on=[\"date\", \"hour\", \"month\", \"weekday\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1684699897132,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "HGCy1fEY74Ee"
   },
   "outputs": [],
   "source": [
    "data_model_v2 = data_model_v2.merge(\n",
    "    weather_data,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"date\", \"hour\", \"month\", \"weekday\"],\n",
    "    right_on=[\"date\", \"hour\", \"month\", \"weekday\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684700172143,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "h10tVN6p8_Xu"
   },
   "outputs": [],
   "source": [
    "## split train, test data\n",
    "train_df, val_df = train_test_split(data_model_v2, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GUycKj99N_3"
   },
   "source": [
    "## Process independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1684700226127,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "l_GKOAPn9Jdz",
    "outputId": "181d4fd7-49a3-4b01-d575-ec9014625a83"
   },
   "outputs": [],
   "source": [
    "target_variable = [col for col in train_df.columns if col.startswith(\"laf\")]\n",
    "target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1684700229915,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "Cl0qsxaI9UNa",
    "outputId": "83248fe4-050f-4247-fa2d-9e7834efd041"
   },
   "outputs": [],
   "source": [
    "y_train = train_df[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1684700238663,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "T5-S66vT9Xdv",
    "outputId": "ba211cd2-b64f-43fc-8f3d-62c0189828ae"
   },
   "outputs": [],
   "source": [
    "y_val = val_df[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684703857408,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "6uxB6J_H9Zi4"
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(target_variable + [\"date\"], axis=1)\n",
    "X_val = val_df.drop(target_variable + [\"date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1684703866553,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "wruUoGhY9pJ3"
   },
   "outputs": [],
   "source": [
    "one_hot_var = [\"hour\", \"month\", \"weekday\", \"object_id\"]\n",
    "numerical_var = [col for col in X_train.columns if col not in one_hot_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1684703869315,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "jN_TfTZ29uS3",
    "outputId": "5acda449-3047-426f-f27c-0652ed1d0252"
   },
   "outputs": [],
   "source": [
    "t = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"OneHot\", OneHotEncoder(handle_unknown=\"ignore\"), one_hot_var),\n",
    "        (\"StandardScaler\", StandardScaler(), numerical_var),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# fit the encoder\n",
    "t.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoder\n",
    "\n",
    "pickle.dump(t, open(\"../model/model_noise_level_file40/encoder.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1684703879767,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "dYCwEhSx9v9P"
   },
   "outputs": [],
   "source": [
    "# create pandas DataFrame from dense matrix\n",
    "X_train = pd.DataFrame(t.fit_transform(X_train), columns=t.get_feature_names_out())\n",
    "X_val = pd.DataFrame(t.transform(X_val), columns=t.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irLjEttq97oS"
   },
   "source": [
    "## Predict laf50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is \"exemplatory\", laf25/75 are run in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2934027,
     "status": "ok",
     "timestamp": 1684703432834,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "6rXj_i3y99Ze",
    "outputId": "167377fe-3a99-4916-ad4c-60ad8ea54203"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../model/model_noise_level_file40/laf50_per_hour_dict\"):\n",
    "    print(\n",
    "        \"Params have already been searched and saved, so instead we just load the file\"\n",
    "    )\n",
    "    params_dict = pickle.load(\n",
    "        open(\"../model/model_noise_level_file40/laf50_per_hour_dict\", \"rb\")\n",
    "    )\n",
    "else:\n",
    "    # Define the model parameters\n",
    "    model_params = {\n",
    "        \"random_forest\": {\n",
    "            \"model\": RandomForestRegressor(),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": randint(50, 100),\n",
    "                \"max_depth\": randint(3, 50),\n",
    "                \"max_features\": [\"auto\", \"sqrt\"],\n",
    "                \"min_samples_split\": randint(2, 20),\n",
    "                \"min_samples_leaf\": randint(1, 10),\n",
    "                \"bootstrap\": [True, False],\n",
    "            },\n",
    "        },\n",
    "        \"gradient_boosting\": {\n",
    "            \"model\": GradientBoostingRegressor(),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": randint(50, 100),\n",
    "                \"learning_rate\": uniform(0.01, 0.5),\n",
    "                \"max_depth\": randint(1, 10),\n",
    "                \"min_samples_split\": randint(2, 20),\n",
    "                \"min_samples_leaf\": randint(1, 10),\n",
    "            },\n",
    "        },\n",
    "        \"xgboost\": {\n",
    "            \"model\": xgboost.XGBRegressor(),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": randint(50, 100),\n",
    "                \"learning_rate\": uniform(0.01, 0.5),\n",
    "                \"max_depth\": randint(1, 10),\n",
    "                \"min_child_weight\": randint(1, 10),\n",
    "                \"gamma\": uniform(0, 1),\n",
    "                \"reg_alpha\": uniform(0, 1),\n",
    "                \"reg_lambda\": uniform(0, 1),\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    params_dict = {}\n",
    "\n",
    "    # Loop through each model in model_params and run RandomizedSearchCV\n",
    "    for model_name, model_info in model_params.items():\n",
    "        print(\"Running RandomizedSearchCV for {}...\".format(model_name))\n",
    "\n",
    "        # Create a RandomizedSearchCV object for the current model\n",
    "        model = model_info[\"model\"]\n",
    "        param_dist = model_info[\"params\"]\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=10,\n",
    "            cv=5,\n",
    "            n_jobs=1,\n",
    "            random_state=7,\n",
    "        )\n",
    "\n",
    "        # Fit the RandomizedSearchCV object to the data\n",
    "        random_search.fit(X_train, y_train[\"laf50_per_hour\"])\n",
    "\n",
    "        # Print the best parameters and score\n",
    "        params_dict[model_name] = random_search.best_params_\n",
    "        print(\"Best parameters for {}: \".format(model_name), random_search.best_params_)\n",
    "        print(\"Best score for {}: \".format(model_name), random_search.best_score_)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimal param dictionary\n",
    "pickle.dump(\n",
    "    params_dict, open(\"../model/model_noise_level_file40/laf50_per_hour_dict\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69174,
     "status": "ok",
     "timestamp": 1684704022668,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "cNzGJHuUKIoW",
    "outputId": "d8c3e6db-d0dd-43ee-9d05-2e9e79464d57"
   },
   "outputs": [],
   "source": [
    "gb_params = params_dict[\"gradient_boosting\"]\n",
    "\n",
    "gb = GradientBoostingRegressor(**gb_params, random_state=7)\n",
    "\n",
    "gb.fit(X_train, y_train[\"laf50_per_hour\"])\n",
    "\n",
    "train_preds = gb.predict(X_train)\n",
    "val_preds = gb.predict(X_val)\n",
    "\n",
    "print(\n",
    "    \"Train RMSE:\", np.sqrt(mean_squared_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    ")\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(val_preds, y_val[\"laf50_per_hour\"])))\n",
    "print(\"Train MAE:\", mean_absolute_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    "print(\"Val MAE:\", mean_absolute_error(val_preds, y_val[\"laf50_per_hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8109,
     "status": "ok",
     "timestamp": 1684704030764,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "E-BLw107KY0c",
    "outputId": "37dbd3fe-a7da-4ff4-9d14-4ad7ed1f2e0e"
   },
   "outputs": [],
   "source": [
    "rf_params = params_dict[\"random_forest\"]\n",
    "\n",
    "rf = RandomForestRegressor(**rf_params, random_state=7)\n",
    "\n",
    "rf.fit(X_train, y_train[\"laf50_per_hour\"])\n",
    "\n",
    "train_preds = rf.predict(X_train)\n",
    "val_preds = rf.predict(X_val)\n",
    "\n",
    "print(\n",
    "    \"Train RMSE:\", np.sqrt(mean_squared_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    ")\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(val_preds, y_val[\"laf50_per_hour\"])))\n",
    "print(\"Train MAE:\", mean_absolute_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    "print(\"Val MAE:\", mean_absolute_error(val_preds, y_val[\"laf50_per_hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18886,
     "status": "ok",
     "timestamp": 1684704049637,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "ogHkWY5yKf1a",
    "outputId": "11550677-7f68-4741-f643-4575e8568af5"
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_params = params_dict[\"xgboost\"]\n",
    "\n",
    "xgb = xgboost.XGBRegressor(**xgb_params, random_state=7)\n",
    "\n",
    "xgb.fit(X_train, y_train[\"laf50_per_hour\"])\n",
    "\n",
    "train_preds = xgb.predict(X_train)\n",
    "val_preds = xgb.predict(X_val)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Train RMSE:\", np.sqrt(mean_squared_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    ")\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(val_preds, y_val[\"laf50_per_hour\"])))\n",
    "print(\"Train MAE:\", mean_absolute_error(train_preds, y_train[\"laf50_per_hour\"]))\n",
    "print(\"Val MAE:\", mean_absolute_error(val_preds, y_val[\"laf50_per_hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1684704118535,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "r50NdVlYKbiN",
    "outputId": "772ff71c-7b33-4413-aedb-32cdc1d4b8fe"
   },
   "outputs": [],
   "source": [
    "plt.scatter(val_preds, y_val[\"laf50_per_hour\"])\n",
    "plt.xlabel(\"y pred\")\n",
    "plt.ylabel(\"y val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1684704122603,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "j5y9j8gkLbRO",
    "outputId": "65fec1c9-a515-44ed-e733-e197df620fb0"
   },
   "outputs": [],
   "source": [
    "r2_score(val_preds, y_val[\"laf50_per_hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 1877,
     "status": "ok",
     "timestamp": 1684704314314,
     "user": {
      "displayName": "Ken Le",
      "userId": "02524318770864979503"
     },
     "user_tz": -120
    },
    "id": "u7Mrg_oXMwk0",
    "outputId": "1c3374d8-58d5-4820-c762-d4c5a976540f"
   },
   "outputs": [],
   "source": [
    "feature_importances = xgb.feature_importances_\n",
    "sorted_idx = feature_importances.argsort()[::-1]\n",
    "sorted_importances = feature_importances[sorted_idx[0:30]]\n",
    "sorted_columns = list(X_train.columns[sorted_idx[0:30]])\n",
    "plt.barh(sorted_columns, sorted_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best model\n",
    "pickle.dump(xgb, open(\"../model/model_noise_level_file40/xgb_laf50_per_hour.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Laf 25/75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"laf25_per_hour\", \"laf75_per_hour\"]\n",
    "model_params_dict = {}\n",
    "for target in targets:\n",
    "    if os.path.isfile(f\"../model//model_noise_level_file40/{target}_dict\"):\n",
    "        print(\n",
    "            \"Params have already been searched and saved, so instead we just load the file\"\n",
    "        )\n",
    "        model_params_dict[target] = pickle.load(\n",
    "            open(f\"../model/model_noise_level_file40/{target}_dict\", \"rb\")\n",
    "        )\n",
    "    else:\n",
    "        # Define the model parameters\n",
    "        model_params = {\n",
    "            \"random_forest\": {\n",
    "                \"model\": RandomForestRegressor(),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": randint(50, 100),\n",
    "                    \"max_depth\": randint(3, 50),\n",
    "                    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "                    \"min_samples_split\": randint(2, 20),\n",
    "                    \"min_samples_leaf\": randint(1, 10),\n",
    "                    \"bootstrap\": [True, False],\n",
    "                },\n",
    "            },\n",
    "            \"gradient_boosting\": {\n",
    "                \"model\": GradientBoostingRegressor(),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": randint(50, 100),\n",
    "                    \"learning_rate\": uniform(0.01, 0.5),\n",
    "                    \"max_depth\": randint(1, 10),\n",
    "                    \"min_samples_split\": randint(2, 20),\n",
    "                    \"min_samples_leaf\": randint(1, 10),\n",
    "                },\n",
    "            },\n",
    "            \"xgboost\": {\n",
    "                \"model\": xgboost.XGBRegressor(),\n",
    "                \"params\": {\n",
    "                    \"n_estimators\": randint(50, 100),\n",
    "                    \"learning_rate\": uniform(0.01, 0.5),\n",
    "                    \"max_depth\": randint(1, 10),\n",
    "                    \"min_child_weight\": randint(1, 10),\n",
    "                    \"gamma\": uniform(0, 1),\n",
    "                    \"reg_alpha\": uniform(0, 1),\n",
    "                    \"reg_lambda\": uniform(0, 1),\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        params_dict = {}\n",
    "\n",
    "        # Loop through each model in model_params and run RandomizedSearchCV\n",
    "        for model_name, model_info in model_params.items():\n",
    "            print(\"Running RandomizedSearchCV for {}...\".format(model_name))\n",
    "\n",
    "            # Create a RandomizedSearchCV object for the current model\n",
    "            model = model_info[\"model\"]\n",
    "            param_dist = model_info[\"params\"]\n",
    "            random_search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=10,\n",
    "                cv=5,\n",
    "                n_jobs=1,\n",
    "                random_state=7,\n",
    "            )\n",
    "\n",
    "            # Fit the RandomizedSearchCV object to the data\n",
    "            random_search.fit(X_train, y_train[target])\n",
    "\n",
    "            # Print the best parameters and score\n",
    "            params_dict[model_name] = random_search.best_params_\n",
    "            print(\n",
    "                \"Best parameters for {}: \".format(model_name),\n",
    "                random_search.best_params_,\n",
    "            )\n",
    "            print(\"Best score for {}: \".format(model_name), random_search.best_score_)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        model_params_dict[target] = params_dict\n",
    "        pickle.dump(\n",
    "            params_dict, open(f\"../model/model_noise_level_file40/{target}_dict.pkl\", \"wb\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running gb, rf, xgb for laf25/laf75 including RMSE/MAE scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_models = {}\n",
    "for target in targets:\n",
    "    gb_params = model_params_dict[target][\"gradient_boosting\"]\n",
    "\n",
    "    gb = GradientBoostingRegressor(**gb_params, random_state=7)\n",
    "\n",
    "    gb.fit(X_train, y_train[target])\n",
    "\n",
    "    train_preds = gb.predict(X_train)\n",
    "    val_preds = gb.predict(X_val)\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(train_preds, y_train[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Val RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(val_preds, y_val[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Train MAE of model {target}:\",\n",
    "        mean_absolute_error(train_preds, y_train[target]),\n",
    "    )\n",
    "    print(f\"Val MAE of model {target}:\", mean_absolute_error(val_preds, y_val[target]))\n",
    "    gb_models[target] = gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models = {}\n",
    "for target in targets:\n",
    "\n",
    "    rf_params = model_params_dict[target][\"random_forest\"]\n",
    "\n",
    "    rf = RandomForestRegressor(**rf_params, random_state=7)\n",
    "\n",
    "    rf.fit(X_train, y_train[target])\n",
    "\n",
    "    train_preds = rf.predict(X_train)\n",
    "    val_preds = rf.predict(X_val)\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(train_preds, y_train[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Val RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(val_preds, y_val[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Train MAE of model {target}:\",\n",
    "        mean_absolute_error(train_preds, y_train[target]),\n",
    "    )\n",
    "    print(f\"Val MAE of model {target}:\", mean_absolute_error(val_preds, y_val[target]))\n",
    "    rf_models[target] = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_models = {}\n",
    "for target in targets:\n",
    "\n",
    "    xgb_params = model_params_dict[target][\"xgboost\"]\n",
    "\n",
    "    xgb = xgboost.XGBRegressor(**xgb_params, random_state=7)\n",
    "    xgb.fit(X_train, y_train[target])\n",
    "\n",
    "    train_preds = xgb.predict(X_train)\n",
    "    val_preds = xgb.predict(X_val)\n",
    "\n",
    "    print(\n",
    "        f\"Train RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(train_preds, y_train[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Val RMSE of model {target}:\",\n",
    "        np.sqrt(mean_squared_error(val_preds, y_val[target])),\n",
    "    )\n",
    "    print(\n",
    "        f\"Train MAE of model {target}:\",\n",
    "        mean_absolute_error(train_preds, y_train[target]),\n",
    "    )\n",
    "    print(f\"Val MAE of model {target}:\", mean_absolute_error(val_preds, y_val[target]))\n",
    "    xgb_models[target] = xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best model\n",
    "import pickle\n",
    "\n",
    "for target in targets:\n",
    "    pickle.dump(\n",
    "        xgb_models[target],\n",
    "        open(f\"../model/model_noise_level_file40/xgb_{target}.pkl\", \"wb\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOV38OW+fMi6VEPMT9Bnj+E",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
